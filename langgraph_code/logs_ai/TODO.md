# MACT LangGraph 향후 작업 계획

## 🚀 즉시 수행 가능한 작업 (Ready)

### 1. ✅ RunPod vLLM 실제 테스트 (완료)
- **목표**: RunPod 환경에서 Qwen3-8B 모델 실제 동작 확인
- **결과**: ✅ 성공적으로 연결 및 응답 확인
- **발견된 문제**:
  - 모델명 `Qwen/Qwen2.5-8B` → `Qwen/Qwen3-8B`로 수정 필요
  - 매우 느린 응답 속도 (각 문항당 10-20분)
  - QWEN3-8B의 verbose한 코드 생성으로 인한 성능 저하

### 2. 대용량 데이터셋 성능 테스트
- **목표**: 500+ 아이템 데이터셋에서 성능 및 안정성 확인
- **작업 내용**:
  - 메모리 사용량 모니터링
  - 스트리밍 저장 검증
  - 중간 진행률 출력 테스트
- **예상 소요**: 1시간
- **우선순위**: High

### 3. 추가 리워드 함수 구현
- **목표**: logp, rollout, combined 리워드 함수 완전 구현
- **작업 내용**:
  - `_select_by_logp()` 실제 로그 확률 기반 구현
  - `_select_by_rollout()` 롤아웃 평가 구현
  - 성능 비교 및 검증
- **예상 소요**: 2시간
- **우선순위**: Medium

## 🔧 시스템 개선 작업 (Enhancement)

### 4. 답변 정확도 개선
- **목표**: 현재 0% 정확도 문제 분석 및 해결
- **작업 내용**:
  - 테이블 조인 로직 검토
  - SQL 실행 엔진 개선
  - 답변 매칭 알고리즘 조정
- **예상 소요**: 3시간
- **우선순위**: High

### 5. 도구 실행 최적화
- **목표**: 코드 생성 및 실행 성공률 향상
- **작업 내용**:
  - 프롬프트 엔지니어링 개선
  - 코드 실행 환경 안정화
  - 오류 복구 메커니즘 추가
- **예상 소요**: 2시간
- **우선순위**: Medium

### 6. 메트릭 시스템 확장
- **목표**: 다양한 평가 지표 추가
- **작업 내용**:
  - BLEU, ROUGE 점수 계산
  - 의미적 유사도 평가
  - 실행 단계별 분석
- **예상 소요**: 1.5시간
- **우선순위**: Low

## 📚 문서화 및 예제 (Documentation)

### 7. 사용자 가이드 작성
- **목표**: 완전한 사용법 문서 제공
- **작업 내용**:
  - 설치 및 설정 가이드
  - 데이터셋 형식 설명
  - 실행 예제 및 결과 해석
- **예상 소요**: 2시간
- **우선순위**: Medium

### 8. API 문서화
- **목표**: 개발자를 위한 상세 API 문서
- **작업 내용**:
  - 노드 인터페이스 문서
  - 상태 관리 시스템 설명
  - 확장 가능한 구조 안내
- **예상 소요**: 1.5시간
- **우선순위**: Low

## 🧪 고급 기능 (Advanced Features)

### 9. 다중 모델 앙상블
- **목표**: 여러 모델의 결과를 조합하여 성능 향상
- **작업 내용**:
  - 모델별 가중치 시스템
  - 투표 메커니즘 구현
  - 성능 비교 분석
- **예상 소요**: 3시간
- **우선순위**: Low

### 10. 실시간 모니터링 대시보드
- **목표**: 실험 진행 상황 실시간 추적
- **작업 내용**:
  - 웹 인터페이스 구현
  - 진행률 및 메트릭 시각화
  - 실시간 로그 스트리밍
- **예상 소요**: 4시간
- **우선순위**: Low

## ⚠️ 알려진 이슈 및 해결 필요

### 🔥 긴급: LangGraph 성능 최적화 필요
- **현재 문제**: 기존 MACT 대비 10-20배 느린 속도
- **주요 원인**:
  1. **QWEN3-8B 코드 생성 품질**: verbose 주석, 문법 오류 빈발
  2. **과도한 LLM 호출**: 단일 문제당 10-20회 API 호출
  3. **LangGraph 오버헤드**: 노드 간 상태 전환 비용
- **해결 방안**:
  - 샘플링 수 감소 (plan_sample=3, code_sample=3)
  - 더 나은 모델 사용 (GPT-4 등)
  - 코드 템플릿 및 캐싱 도입
  - 배치 처리 구현

### 현재 정확도 문제 (일부 해결됨)
- **QWEN3-8B**: 일부 문제에서 답변 생성하지만 정확도 낮음
- **GPT-4o-mini**: 실행되지만 정확도 이슈 있음
- **해결 방안**: 프롬프트 엔지니어링, 코드 생성 로직 개선

### RunPod vLLM 연결 (해결됨)
- **결과**: ✅ 정상 연결 및 응답 확인
- **모델명**: `Qwen/Qwen3-8B` 사용 (이전 `Qwen/Qwen2.5-8B`는 미지원)

## 📅 권장 작업 순서 (업데이트됨)

### 🔥 최우선 (성능 최적화)
1. **LangGraph 성능 최적화**
   - 샘플링 수 감소 (plan_sample=3, code_sample=3)
   - 코드 템플릿 및 프롬프트 개선
   - 불필요한 재시도 로직 최소화

### 📈 다음 단계 (안정화)
2. **답변 정확도 개선**
   - 프롬프트 엔지니어링
   - 코드 생성 로직 개선
   - 테이블 조인 로직 검증

3. **모델별 최적화**
   - GPT-4 시리즈 테스트
   - QWEN3-8B 프롬프트 특화 최적화
   - 모델별 최적 파라미터 조정

### 🎯 완성도 향상
4. **대용량 데이터셋 테스트**
5. **추가 리워드 함수 구현**
6. **사용자 가이드 및 문서화**

---

**작성일**: 2025-09-28 18:30:00
**마지막 업데이트**: QWEN3-8B RunPod 테스트 완료, 성능 이슈 발견